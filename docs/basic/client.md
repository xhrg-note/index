## 客户端设计的一些考虑点


#### 一、为什么要做客户端设计

平常我们在做rpc服务化设计的时候，会有服务消费者的设计。几乎所有的组件都有客户端，比如以下客户端：：：

- mysql-client
- redis-client
- mq-client
- http-client
- rpc-client
等等，而好的客户端，所包含的功能，肯定不会是发起一个请求，得到结果这么简单。好的客户端，尤其是分布式环境，会包含非常多的功能。因为场景的需要，这些功能可能是必须的。

#### 二、服务发现

一般分布式环境，服务的提供者都是有多个节点(实例)。并且提供者可能会动态的增加和删除节点。一般服务提供者启动后，会把自己的路由信息[比如自己的地址，端口，一些接口路径，方法，版本号等]写入注册中心[如：zookeeper，etcd]。客户端根据固定的注册中心的地址作为配置文件或者环境变量固定读取到客户端进程中。然后到注册中心找到路由信息后，放到自己本地缓存里面，每次请求过来从缓存中拿到地址来发起请求，比如http请求的ip。或者根据读取到的服务提供者的地址，生成某个client对象缓存到本地。并且，客户端还需要监听注册中心的数据变化，当注册中心的数据发生变化的时候，客户端需要对本地缓存列表进行改动。

不支持在 Docs 外粘贴 block
之所以需要服务发现的原因是
- 服务提供者可能会增加。
- 服务提供者可能会减少。
- 消费者上报自己的信息。

#### 三、负载均衡(Load Balance)

客户端向服务提供者发起请求，而服务提供者可能有5个实例，那么这次请求我们该访问哪个节点呢？一种比较理想的效果就是，我有5个实例，那么请求过来后发往实例1，下次实例2，下下次实例3.....，总不能每次都请求到实例1，对吧。这个时候就需要用到负载均衡，负载均衡一般可能需要有这几种。
- 随机算法。
- 轮询算法。
- 一致性哈希负载均衡。
- 加权轮询算法。
- 其他更多复杂算法。
3.1、随机算法
随机算法比较简单，当拿到服务提供者地址的时候，比如说有3个地址。编号是0，1，2。我们可以本地生成3个客户端，然后放入数组中。
Client client0 = new Client(ip0);
Client client1 = new Client(ip1);
Client client2 = new Client(ip2);
Client[] clientList = new Client[4]{client0, client1, client2}
int i = new Random().next(3)-1;//获得5以下的随机数，比如0,1,2，3，4，
client = clientList[i];
client.call()
3.2、轮询算法
轮询算法类似随机算法，只不过本地需要缓存一个整数 i ，然i做加1操作。当i等于节点个数的时候，继续从0开始。

Client client0 = new Client(ip0);
Client client1 = new Client(ip1);
Client client2 = new Client(ip2);
int i = 0；
Client[] clientList = new Client[4]{client0, client1, client2}
index = i++；
if (index == clientList.size){
   i = 0;
}
client = clientList[index];
client.call()
3.3、一致性哈希算法
一致性哈希算法的目的是为了相同的请求参数每次都打到不同的主机。并且还可以支持动态的增加主机和删除主机后，依然大概率还能做到相同的请求参数每次都打到不同的主机。简单介绍就是有一个环，这个环拆分的很细，环上的节点很多，然后把主机按照顺序分散到这个换上。比如




如图所示，我们假设这个园上有非常多的点，假设1-100000，我把1，2，3拆散放上去，分了2组。然后根据请求参数计算得到一个数字，然后在根据圆上的点的总数取模得到一个数字，再根据顺时针，找到最近的一个节点，就是要路由到的节点。


3.4、加权轮询算法

加权轮询算法，比如说有3个节点。abc。没有权重的时候我们访问应该是abc，加了权重后可能是abbccc这样，然后再进行随机，得到，acbcbc这样。就是加权轮询算法。

以上是几种比较常见的随机算法，而因为业务场景的需求，也有很多更复杂的负载均衡算法，可以根据业务场景去设计。去学习。

#### 四、服务容错

分布式环境的接口一般要求幂等，也就是一个接口，调用一次或者多次后结果是一致的。不会产生数据的不一致。而对于查询操作我们知道，就算不做特殊处理，也是天然秘等的。如果一个接口调用A主机的服务，发现网络异常，这个时候，可能需要调用B主机。同时根据失败率把B主机从本地路由信息表做特殊标记。服务容错一般有这几种
- 失败自动切换
- 失败直接返回
- 失败忽略
- 并行调用
4.1、失败自动切换
如果我们的客户端，比如redis，或者服务化接口的服务消费者。请求一个节点A，发出一个get请求，然后服务网络异常了。那么这个时候，有一种情况我们可能需要请求节点B。当B成功后则把请求返回。这种就是失败自动切换，这种情况一定要保证节点的幂等性。像put操作则不会建议继续访问下一个节点，除非你的客户端代码能够明确知道节点A并没有收到请求，而不是处理了一般。
4.2、失败直接返回
在没有做特殊处理的情况下，我们根据路由信息表，找到一个节点的地址或者客户端句柄，发出请求，无论成功或者失败都直接返回。这种情况是不做特殊处理的直接结果。
4.3、失败忽略
有一些请求我们对结果要求并不高，不在乎结果，比如说一些日志埋点的反馈等。那么客户端请求后，无论成功失败，都返回同样的结果。
4.3、并行调用
同时发起多个请求，当任何一个得到结果的时候直接返回。优点是请求最终端的反馈会快，缺点是浪费不必要的计算和网络资源。

还有其他更多的服务容错设计方式，都需要根据具体业务场景去设计。


#### 五、节点心跳(HeartBeat)
在注册中心有5个服务提供者注册的信息，假设有一个节点突然挂了，但是注册中心的数据并没有拿掉。或者一个节点出现假死，请求结果不会返回。这个时候就需要心跳机制。从客户端到服务端，保持一个tcp链接，每隔N长时间，互相发送一次请求。客户端给服务端发送1000，服务端返回10001。如果发生异常情况，客户端需要马上从本地的的路由信息表把这个节点标记起来。并且心跳不断，以防网络抖动，所以可能还是需要恢复服务的。心跳次数和恢复时间，都是可以根据实际业务场景而定。

一般tcp就有心跳机制，SO_KEEPALIVE，注意这里的SO_KEEPALIVE和[http的keepalive]没有任何关系，只是名称一致。使用tcp的keepalive有这样的效果，假设服务端发生异常，那么客户端能够收到tcp的异常断开事件。但是tcp的keepalive有以下问题：：
- 只能保证链接存活，并不保证链接是否可用。
- 仅仅是规范的东西，操作系统实现上未必保证。
- keepalive可以开启和关闭，你无法保证主机一定是开启的。
- 异常情况，如果机器断电，异常退出，服务假死，可能一端并不能收到事件。
- 无法加入业务场景。比如我想要一个心跳接口，不仅检测到客户端和服务端之间的网络，还能检测到数据库是否可用。

所以客户端设计的时候，还需要加入业务层的心跳机制。业务层心跳，一般是周期性的给另一个端发送一个请求，比如说3秒，甚至几十几百毫秒。这个请求具体根据客户端协议而来，可能是http的，也可能是tcp层的。另一端收到请求后，可以直接返回一个约定数据，也可以做一些本地检查后返回约定数据。而客户端如果发现，请求返回有误，无法返回，返回慢，返回错误等结果，则可以在本地路由信息表摘除对该节点的路由信息和客户端句柄。


#### 六、面向企业内部
以上几个点都是通用设计点，但是一个sdk要给公司内部人员使用的时候，还会有新的问题。比如以下几点。
- 日志。一般情况下，sdk打的日志，如info日志，error日志，会和业务同学的日志混在一起。然后有同事让你去排查问题。沟通了一些基本信息后，要看日志，发现日志太多。这个时候，可能需要把日志打印到一个独立的地方，比如说/data/logs/my-sdk/xxx.log或者当前用户目录下的某个位置，一旦业务同学出问题，我们只需要让他把我们知道的那个日志文件拿来即可。
- 异常。因为sdk没有返回异常，或者结果不正确的情况时有发生。到底是sdk的问题，还是业务的问题。这个时候，客户端必须明确异常和返回值。
- 缓存client。你是否遇到过，有同事在代码的方法[函数]中Client client = new Client。假设有1000次请求，则new一千次。所以client有时候也需要设置缓存。就是他在方法中new Client的时候，如果是第二次则返回第一次的结果。缓存的key，应该是对象的初始化参数。
- sdk版本上报。随着业务的推荐，使用sdk的人会原来越多。会有不同的业务，不同的团队使用sdk。那么sdk的版本，sdk的使用团队这些信息，有可能是需要被使用的。
- 更多。更复杂的如，业务的系统信息，cpu，内存，堆栈，都是可以在不影响业务的情况下进行收集。

#### 七、客户端设计其他点

以上是一般的客户端设计中可能需要包含的一些点。在分布式环境下，可能还需要更多的设计。这些设计有可能是通用的，比如网络层的，有可能是业务层的。可能不同功能的设计都不一样。这些都需要不断的挖掘，不断的根据具体业务场景去设计。



